* 持续交付文集

假设大家已经熟悉
- 自动化构建
- 持续集成
- build pipeline
- 自动化测试

超链接引用，将不同的内容模块化，不尝试平铺直述
假设用户可以从任何一部分开始读起，碰到需要了解的部分可以索引到其他部分
引用既有资源

**** TODO 配图
**** TODO 文字修改
**** TODO 二级标题
**** TODO 脚注
**** TODO 索引


本文讲述了互相集成的多个产品团队环境下的持续交付、团队组织等内容。

** 引言：持续交付和持续部署

持续交付是目前的一个挺火的概念，它所描述的软件开发，是从原始需求识别到
最终产品部署到生产环境这个过程中，需求以小批量形式在团队的各个角色间顺
畅流动，能够以较短地周期完成需求的小粒度频繁交付。频繁的交付周期带来了
更迅速的对软件的反馈，并且在这个过程中，需求分析、产品的用户体验和交互
设计、开发、测试、运维等角色密切协作，相比于传统的瀑布式软件团队，更少
浪费。

持续交付是经典的敏捷软件开发方法（例如XP，scrum）的自然延伸，以往的敏捷
方法并没有过多关注开发测试前后的活动，例如前期的需求分析，产品的用户体
验设计，产品的部署和运行维护等。随着伴随着敏捷的很多思想和原则在前后端
领域的运用和升华，以及UX、DevOps等实践的逐渐兴起，我们在持续交付这个新
的大概念下看到了敏捷方法和更多实践活动的结合和更大范围的应用。

# flickr等的部署频率

在这里我不想过多探讨这个大的概念，而是只想就整个软件交付过程中的一段进
行探讨。假设现在需求已经明确，并且已经被划分为小的单位（例如用户故事
user story），我们着重看一看从开发人员拿到用户故事，到这些用户故事被实
际部署到生产环境上的这个过程。实际上这个过程当然是越短越好，特别是对于
急需获得用户反馈的软件产品（例如很多互联网产品）。如果我们做的每一个用
户故事，甚至是我们的每一次提交，都能够被自动地部署到生产环境中去，那么
这种频繁近乎持续地部署，对于很多软件开发团队来说，就成了值得追求的目标。

持续部署和交付之间的另外一个区别在于，很多时候我们可以选择将功能部署，
但是却不向用户开放(dark launch)。这样做的目的在于，有些功能需要部署到
生产环境中，接受大量真实用户的非直接测试（facebook的例子）；或者有时候
希望把一些小的功能组合起来一起展现给用户。因此，部署可以很频繁，然而实
际交付给用户使用则可能根据计划，比部署的频率低。

# dark launch
# feature toggle

持续部署，依赖于整个团队对所写代码的信心，这种放心，不仅是开发这段代码
的人对自己写的代码的自信，也不是少数人的主观感觉，必须是团队或者组织的
所有成员都抱有的基于客观事实的信心。因此，如何能够让任何新的修改都能够
迅速地、有信心地被部署到生产环境，就成了一个值得解决的问题。后面我们仔
细讨论，自动化测试是建立这种信心的根本保证。

在团队具备信心的基础上，要实现产品的持续部署，还需要有自动化构建流水线
(build pipeline)。以自动化生产线作比，自动化测试只是其中一道质量保证工
序，而要将产品从原料（需求）转变为最终交付给客户的产品，自动化的生产线
是中枢一般的存在。特别对于软件产品，多个产品往往要集成在一起才能为客户
提供服务。多个产品的自动化构建流水线的设计也就成了一个很重要的问题。

产品在从需求到部署的过程中，会经历若干种不同的环境，例如QA环境、各种自
动化测试运行环境、生产环境等。这些环境的搭建、配置、管理，产品在不同环
境中的具体部署，都需要完善的工具支持。缺乏这些工具，生产流水线就不可能
做到完全自动化和高效。

因此，持续部署靠自动化测试建立信心，以构建流水线贯穿始终，靠各种工具实
现高效自动化和保持低成本。在下面我将详细谈论一下这几部分的内容。


** 自动化测试

如何能够保证我们写出来的代码既能准确实现我们的新功能，又能够不破坏既有
的功能？唯有靠完善的测试。而当我们开始追求频繁地甚至是持续地部署的时候，
自动化测试是唯一的能够让我们持续反复地验证软件的方法。如果一个产品具有
完备的自动化测试用例，那么任何一次对软件的修改都能够得到自动化地回归验
证，如果验证通过，我们就具备了将这些修改部署到生产环境中的信心。自动化
测试的质量直接决定了我们能否具有持续部署的信心。

关于自动化测试，有很多著作详细地讲述了自动化测试的设计、实现技巧等，这
里不再尝试重复这些内容。我想以一个web应用为例，举例分析一下到底需要些什
么样的测试才能够让我们建立对这个产品的信心。

# pic: web example

这个简化的例子里包含了三个软件开发团队（A、B、C），这几个团队各自有自己
的一些产品，最终他们的产品组合起来给用户提供完整的体验。A团队的产品包含
了3个主要模块。其中fetcher集成了B和C的产品，定时从其中获取数据，经过分
析后存入store；frontend则会从store中获取数据，以web界面与用户进行交互。
frontend同时还和其他一些组织外的第三方服务集成（例如twitter，weibo等）。

这里不妨再对A的产品所采用的技术进行进一步限定，以方便我们之后的有些讨论。
我们不妨假定frontend和fetcher都基于java平台，都是标准的j2ee应用，store
采用mysql。frontend和fetcher都通过web api（可能是RESTful web api）于第
三方应用集成。在生产环境中，frontend和fetcher都会部署在tomcat+apache服
务器上。

我们现在可以以这个web应用为对象，考察一下如果我们在fetcher或者frontend
里修改了代码，诸如添加了新的功能，或者修复了bug，我们怎么样能使这些修改
有信心地从开发人员的机器流入到产品环境中去。虽然我们以这个简化的web产品
作为讨论对象，但是我们接下来讨论的大部分内容并不局限于web应用。

简单地讲，A产品的测试大概包含两个方面：
- 功能方面的测试。包含A产品自身功能的测试，A产品和B、C产品以及twitter
  等外部应用的集成测试。
- 性能测试。在功能正确实现的基础上，产品的性能也必须满足预期。

根据分层自动化测试的理念，功能方面的测试又可以分成如下几层。

最上层的是A和B、C以及外部应用的集成测试。测试模拟真实用户和产品的交互，
和真实的B、C以及外部应用通信，验证A系统功能的正确和完备。这种测试通常需
要完整部署A以及相关的所有应用（如B、C），在真实的网络环境下执行。集成测
试涉及的应用多，测试基础环境准备复杂，运行时间也通常较长，是最为昂贵的
测试。

在A产品和其他产品接口确定的情况下，如果我们将A的外部依赖应用全部打桩
（stub），只关注于A产品自身的功能实现情况，这种测试我们估且称之为A的功
能测试（或者A的验收测试）。在例子中，就意味着我们会将fetcher、db还有
frontend都部署起来，将所有外部应用如B、C、weibo都进行打桩。大家可能会
觉得其上层的集成测试已经可以测到A的功能了，何必搞这么复杂又引入打桩？
但是这一层测试相比于上层的集成测试有这么几个好处：
- 成本更低。单纯部署A比部署整个产品族的成本更低；而且因为A的外部依赖都
  是stub，因此执行速度也会更快；而且因为打桩了外部依赖，不再需要考虑其
  他产品的测试数据（fixture）准备，功能测试的测试数据准备的工作量相对也
  会减少。大家可能认为打桩本身是个很高的成本，但是实际上有很多工具和库
  以及让打桩变的很容易，例如对于web api，采用嵌入式web服务器可以很容易
  实现这些api的模拟，这部分的成本很低。
- 更稳定。一般来讲，牵涉的应用越多，测试越不稳定。在B、C等都是真实应用
  的情况下，任何应用中的问题都可能导致测试失败，甚至网络、部署上的问题
  也可能导致测试失败。因此A的功能测试相对来讲更加稳定。
- 覆盖率高。因为成本更低，因此可以以同样成本编写和维护更多测试。以web应
  用为例，目前有很多功能测试工具可以针对各种web交互进行测试。而且在外部
  依赖打桩的情况，可以简单操纵stub模拟外部依赖接口的各种特殊情况，达到
  对A在各种接口异常情况下功能的测试覆盖。
- 测试组织更良好。假设A、B、C都能够以这种方式对自身的功能进行完整验证，
  那么A、B、C组成的整个系统的集成验证就可以只验证他们之间接口假设的正确
  性，因此集成测试就可以只依靠贯穿3个产品功能的少量的测试，就可以保证
  整个产品族的功能正确。

A产品的功能测试通常需要将A产品部署后才能进行。例如fetcher和frontend需
要部署到tomcat里，store需要准备好mysql，还要将各自的配置文件写好，然后
运行测试。非但如此，为了确信这个产品部署到生产环境能运行地和跑功能测试
时一样，我们还要确保功能测试运行的环境和实际生产环境尽量保持一致，例如
运行在同样的操作系统上，同样版本的tomcat、mysql服务器等。

这种分层测试的思想在整个自动化测试的设计和组织上都有体现。下层的测试相
对于上层的测试，覆盖的范围更小，但是对功能的覆盖更全面。按照这个思路，
A产品的功能测试下，又可能有fetcher和frontend两个组件自己的功能测试，而
在fetcher内部，又可能有各层各模块的测试，再有针对每个类、函数或者方法的
单元测试。

# pic 自动化测试图解

# pic 各种自动化测试图解

所有这些测试，以一个金字塔的形式，组合在一起确保A以及整个产品族的功能
正确和完备，如果这些测试都能够通过，那么团队就有信心将自己的代码修改部
署到产品环境中去，这些自动化测试，就构成了产品的验证和功能防护网。

这里不得不提一下测试驱动开发（TDD）。前面提到了这么多的测试，如果系统
在设计上对测试不友好，以致很难甚至无法写自动化测试，那么自然无法谈用自
动化测试来保障功能。如果尝试先写功能后补测试，甚至希望另一个团队来写自
动化测试，实践证明，想拥有完善、组织良好的测试用例也只是一个美好的愿望。
测试驱动开发不仅能够很大程度上驱动出对测试友好的软件设计，也从一开始就
保障了高测试覆盖率，以及组织良好、干净的测试代码。

*** 性能测试

性能测试也是产品交付之前的一道重要保障。在实际交付到用户手中之前，必须
保证现有的系统能够有足够的容量支撑预期的用户量。性能测试的设计和实现同
样已经有很多资源可以参考，这里也不再尝试重复已有内容。

性能测试和功能测试的最大不同在于，很大一部分性能测试是需要运行在和实际
产品环境完全相同的环境，很多时候甚至直接用生产环境作为性能测试的环境。
从准备这个环境以及自动化整个测试过程来讲，和功能测试并没有本质上的不同，
而只有简单与复杂的区别，我们会在之后的工具和环境中详细讨论这些内容。


** 环境(environment)

环境是一个比较宽泛的概念。这里要说的环境，特指我们的应用所部署的环境。
软件的开发到部署，所涉及到的环境至少有如下几种：

首先是开发环境，这里狭义地指开发者的单机开发环境。开发环境是任何应用首
先运行的环境，任何代码都会首先在开发环境中首先得到一些手工或者自动的验
证。自动化测试首先也会在开发环境上运行。开发环境未必和生产环境高度相似，
例如A产品可能部署在linux平台上，而开发却用windows或者mac；生产环境中用
的是tomcat，而开发环境中用jetty来作为j2ee容器。


# 产品的自动化构建(automatic
# build)可能会在开发环境中启动一个轻量级的web server，将自己的应用部署上
# 去，然后自动化地运行功能测试。视产品的复杂程度，可能还需要在开发环境中
# 部署一个数据库，或者其他外部应用的stub。

# 解释一下自动化构建

然后是生产环境（production环境）。这是最为重要的环境，配备有最高级的硬
件设备，部署着所有的应用，集成在一起为其客户提供服务。为了保证性能和稳
定性，多半会运行load balance软硬件，拥有良好的安全配置。服务器们被安置
在良好的物理环境中，并被时刻监控着运行状态。总之，这是最为复杂、重要的
环境。

在开发环境和生产环境之间有很多环境，这些环境的复杂程度介于开发和生产环
境之间。

# 环境图

例如QA环境。顾名思义这是给大家进行功能测试的环境，大家未必只是QA们，而
这里功能测试多半是手工。这个环境通常和产品环境具有一定的相似度，会部署
一些真实的第三方应用。这个QA环境有时候也会兼用作演示(showcase)环境，抑
或将演示环境独立出来。

除了这个QA环境，还有一系列用于自动化构建、自动化测试的环境。这些环境和
自动化以及持续集成紧密关联。

比如运行A的功能测试时A所部署的环境（通常被称作staging环境）。这个环境和
A的生产环境极度类似，因为我们希望这些功能测试好像就是在测真实部署的A产
品，这样一旦测试通过，我们就可以放心地将A部署。这种类似体现在：
- 相同的服务器、网络环境。两个环境下的服务器操作系统、服务器软件首先要
  完全相同，用同样的软件包安装，系统的配置也要完全相同。可以说，
  staging环境中的机器要和生产环境中的机器几乎完全一样。网络环境也要相
  似。相似度越高，因为环境不同而引起的潜在问题就越少。如果产品部署到云
  计算环境中（例如amazon、heroku等），我们很容易建立任意个配置相同的机
  器。
- 相似的拓扑结构。生产环境中为了提升系统性能和容量通常会采用负载均衡进
  行水平扩展。例如我们可能部署多个frontend，store也可能是一个mysql集群。
  staging环境不需要这么多服务器，但是A产品部署的基本拓扑结构应该保持相
  同。
- 相同的部署方法。如果生产环境中会部署A的rpm包，那么staging环境中也必
  须采用rpm包形式部署；反之如果采用脚本或者chef、puppet等工具，staging
  环境也必须用同样的方法。否则部署方法不同，无法保证在生产环境中部署的
  结果和staging环境中一样，也就增加了出问题的风险。

staging环境之所以有这个称谓，就在于它和生产环境的相似。而这种相似，正
是我们进行持续部署的信心所在。

运行A、B、C的集成功能测试时A、B、C所部署的环境，和上面说到的A的staging
环境很相似，不过范围更大，部署了更多的产品，因此常常也叫端到端（end to
end，e2e）测试环境。这个环境，也是和要尽量和生产环境类似，如果说A的
staging环境模拟的是生产环境中A的那部分，e2e环境就是模拟的整个组织的生产
环境。

很多时候，如果我们必须在A的staging环境下开发和调试功能测试的话，在日常
开发过程，尤其是TDD过程中，效率往往让开发人员无法忍受。开发阶段的反馈
周期往往必须保持在数秒的级别，超过10分钟就让人无法忍受。例如junit单元
测试，每个函数的编写过程中可能都要修改和运行n次，超过几秒就让人无法接
受。而功能测试虽然天生就更复杂些，但是如果整套测试如果需要超过10分钟甚
至更久，作为开发人员就不太会频繁地运行这部分测试。在这样的背景下，就产
生了很多优化手段，它们的目的都是为了缩短自动化测试以及整个自动化构建
（automatic build）过程的运行时间。

目前已经有很多优化手段（引用）。例如，不再将A的各个组件部署到staging环
境中，而是部署到开发环境中，采用轻量级容器如jetty来代替tomcat，采用内存
数据库代替mysql等。也可以采用诸如htmlunit的框架代替selenium来编写web功
能测试。这些手段的最终目的都是希望在开发阶段能够以最小的成本、最快的速
度来运行尽可能的自动化验证，以获得尽可能快的反馈。

在优化的环境中运行A的功能测试，固然不能让我们获得和在staging环境下运行
测试相同的信心，但是实践中，在很多情况下，已经能够提供足够高的可信度，
这种可信度对于某些非关键性产品来说，可能已经足够让他们放心将产品部署到
生产环境中去了。与此同时，带来的是开发效率和质量的大幅度提升。

最后还有持续集成(CI, continuous integration)环境。这是持续集成服务器用
来运行它自己（包括它的agents）以及进行产品的自动化构建的环境。CI服务器
就相当于一个开发人员，自动地监控代码库的变化，一旦有变化就自动运行自动
化构建。CI服务器会在这个环境中运行自动化构建的所有内容，作为持续部署的
中枢，像流水线一样贯穿整个开发、测试、部署过程。

这么多环境的管理和维护，本身就构成了一个巨大的问题。在传统的基于物理机
器的运维时代，这么多环境的安装、维护成本高昂，因此极易造成一套环境多用
途、多团队共享的情况，无法保证环境的干净、可靠。但在云计算资源逐渐可能
会低于电费的今天，软件团队将能够借助于虚拟机和云计算，以更低的成本去按
需创建各种环境，甚至开发环境也可以用虚拟机代替。可以说，云计算是持续交
付的基石。

*** TODO 云环境会让这些环境的维护变得更加简单

** 持续集成
   
持续集成作为敏捷方法的一项核心实践，由来已久（马老的文章）。在持续交付
中，持续集成作为整个交付过程的中枢，发挥着至关重要的作用。

前面说过，我们希望我们对软件的修改能够快速、自动化地经过测试和验证，然
后部署到生产环境中去。在自动化测试和环境都具备情况下，开发人员除了在本
地运行自动化构建进行验证外，剩下的工作就主要由持续集成服务器来帮忙完成。

# pic ci pipeline for A

提交门的概念

build pipeline概念

*** 单个产品的持续集成

*** 多个产品持续集成

** 部署

** 工具论

CI服务器选择

三层工具论及各层工具的选择
